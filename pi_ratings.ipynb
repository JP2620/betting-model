{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo para apuestas Premier League\n",
    "\n",
    "- El predictor estÃ¡ basado en el Pi rating\n",
    "- Primero cargamos en dataframes los datos de la temporada actual y la anterior, se usa  \n",
    "  la temporada anterior para calcular los elos iniciales de la actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandasql as pdsql\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# current_season: str = f\"{sys.argv[1]}-{int(sys.argv[2]) - 2000}\"\n",
    "# last_season: str = f\"{int(sys.argv[1]) - 1:02d}-{int(sys.argv[1]) - 2000:02d}\"\n",
    "\n",
    "first_season: str = \"2018-19\"\n",
    "last_season: str = \"2023-24\"\n",
    "\n",
    "\n",
    "full_df: pd.DataFrame = pd.DataFrame()\n",
    "for season in range(int(first_season[:4]), int(last_season[:4]) + 1):\n",
    "    season_str: str = f\"{season:02d}-{season + 1 - 2000:02d}\"\n",
    "    season_df: pd.DataFrame = pd.read_csv(f\"Datasets/bundesliga/{season_str}.csv\")\n",
    "    season_df[\"Season\"] = season_str\n",
    "    full_df = pd.concat([full_df, season_df])\n",
    "full_df.reset_index(drop=True, inplace=True)\n",
    "full_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definimos funciones  para manipular rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_BASE: int = 10\n",
    "ERROR_CONSTANT: int = 3\n",
    "HOME_PERFORMANCE_LEARNING_RATE: int = 0.7 # \\gamma\n",
    "GOAL_PERFORMANCE_LEARNING_RATE: int = 0.035 # \\lambda\n",
    "\n",
    "def get_new_pi_rating(rating_H_H: int, rating_H_A: int, rating_A_H: int, rating_A_A: int, score_H: int, score_A: int) -> Tuple[int, int, int, int]:\n",
    "  expected_goal_diff = get_expected_goal_diff(rating_H_H, rating_A_A)\n",
    "  observed_goal_diff = score_H - score_A\n",
    "  error = abs(expected_goal_diff - observed_goal_diff)\n",
    "  weighted_error_H = weighting_error(error) if expected_goal_diff < observed_goal_diff else -weighting_error(error)\n",
    "  weighted_error_A = weighting_error(error) if expected_goal_diff > observed_goal_diff else -weighting_error(error)\n",
    "\n",
    "  new_rating_H_H = rating_H_H + weighted_error_H * GOAL_PERFORMANCE_LEARNING_RATE\n",
    "  new_rating_H_A = rating_H_A + (new_rating_H_H - rating_H_H) * HOME_PERFORMANCE_LEARNING_RATE\n",
    "  new_rating_A_A = rating_A_A + weighted_error_A * GOAL_PERFORMANCE_LEARNING_RATE\n",
    "  new_rating_A_H = rating_A_H + (new_rating_A_A - rating_A_A) * HOME_PERFORMANCE_LEARNING_RATE\n",
    "\n",
    "  return (new_rating_H_H, new_rating_H_A, new_rating_A_H, new_rating_A_A)\n",
    "\n",
    "def get_expected_goal_diff(rating_h_h, rating_a_a) -> float:\n",
    "  if (rating_h_h >= 0):\n",
    "    expected_goals_h = 10 ** np.abs((rating_h_h / ERROR_CONSTANT)) - 1\n",
    "  else:\n",
    "    expected_goals_h = - (10 ** np.abs((rating_h_h / ERROR_CONSTANT)) - 1)\n",
    "  if (rating_a_a >= 0):\n",
    "    expected_goals_a = 10 ** np.abs((rating_a_a / ERROR_CONSTANT)) - 1\n",
    "  else:\n",
    "    expected_goals_a = - (10 ** np.abs((rating_a_a / ERROR_CONSTANT)) - 1)\n",
    "  \n",
    "  return expected_goals_h - expected_goals_a\n",
    "\n",
    "\n",
    "\n",
    "def weighting_error(goal_diff: int) -> float:\n",
    "  return ERROR_CONSTANT * math.log(goal_diff + 1, LOG_BASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams = pdsql.sqldf(\"SELECT DISTINCT HomeTeam as TEAM FROM full_df\")\n",
    "df_teams[\"H_RATING\"] = df_teams[\"A_RATING\"] = 0.0\n",
    "\n",
    "# set ratings as float\n",
    "df_teams[\"H_RATING\"] = df_teams[\"A_RATING\"].astype(float)\n",
    "df_stats = pd.DataFrame()\n",
    "df_stats[\"RATING_DIFF\"] = df_stats[\"RESULT\"] = 0\n",
    "\n",
    "for index, row in full_df.iterrows():\n",
    "  ratings_diff= df_teams.loc[df_teams[\"TEAM\"] == row[\"HomeTeam\"], \"H_RATING\"].values[0] - df_teams.loc[df_teams[\"TEAM\"] == row[\"AwayTeam\"], \"A_RATING\"].values[0]\n",
    "  result = 1 if row[\"FTHG\"] > row[\"FTAG\"] else 0 if row[\"FTHG\"] == row[\"FTAG\"] else -1\n",
    "\n",
    "  df_stats.loc[index, \"RATING_DIFF\"] = ratings_diff\n",
    "  df_stats.loc[index, \"RESULT\"] = result\n",
    "\n",
    "  full_df.loc[index, \"RATING_DIFF\"] = ratings_diff\n",
    "  full_df.loc[index, \"H_RATING\"] = df_teams.loc[df_teams[\"TEAM\"] == row[\"HomeTeam\"], \"H_RATING\"].values[0]\n",
    "  full_df.loc[index, \"A_RATING\"] = df_teams.loc[df_teams[\"TEAM\"] == row[\"AwayTeam\"], \"A_RATING\"].values[0]\n",
    "  \n",
    "  new_elos: Tuple[int, int, int, int] = get_new_pi_rating(\n",
    "    df_teams.loc[df_teams[\"TEAM\"] == row[\"HomeTeam\"], \"H_RATING\"].values[0],\n",
    "    df_teams.loc[df_teams[\"TEAM\"] == row[\"HomeTeam\"], \"A_RATING\"].values[0],\n",
    "    df_teams.loc[df_teams[\"TEAM\"] == row[\"AwayTeam\"], \"H_RATING\"].values[0],\n",
    "    df_teams.loc[df_teams[\"TEAM\"] == row[\"AwayTeam\"], \"A_RATING\"].values[0],\n",
    "    row[\"FTHG\"],\n",
    "    row[\"FTAG\"]\n",
    "    )\n",
    "                                                 \n",
    "  df_teams.loc[df_teams[\"TEAM\"] == row[\"HomeTeam\"], \"H_RATING\"] = new_elos[0]\n",
    "  df_teams.loc[df_teams[\"TEAM\"] == row[\"HomeTeam\"], \"A_RATING\"] = new_elos[1]\n",
    "  df_teams.loc[df_teams[\"TEAM\"] == row[\"AwayTeam\"], \"H_RATING\"] = new_elos[2]\n",
    "  df_teams.loc[df_teams[\"TEAM\"] == row[\"AwayTeam\"], \"A_RATING\"] = new_elos[3]\n",
    "\n",
    "\n",
    "df_teams.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write full_df to csv\n",
    "full_df.to_csv(\"Datasets/premier/full_df.csv\", index=False)\n",
    "df_teams.to_csv(\"Datasets/premier/df_teams.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BINS = 28\n",
    "# Minimum and maximum rating diffs\n",
    "min_rating_diff = df_stats[\"RATING_DIFF\"].min()\n",
    "max_rating_diff = df_stats[\"RATING_DIFF\"].max()\n",
    "print(df_stats[\"RATING_DIFF\"].min())\n",
    "print(df_stats[\"RATING_DIFF\"].max())\n",
    "\n",
    "# Create bins by their left edge\n",
    "bins = np.linspace(min_rating_diff, max_rating_diff, BINS)\n",
    "# take into account the left most and right most bins\n",
    "bins[0] = bins[0] - 2\n",
    "bins[-1] = bins[-1] + 2\n",
    "\n",
    "# Merge bins so that each bin has at least 20 observations\n",
    "while True:\n",
    "  hist, bin_edges = np.histogram(df_stats[\"RATING_DIFF\"], bins=bins)\n",
    "  if (hist.min() > 20):\n",
    "    break\n",
    "  else:\n",
    "    bins = np.delete(bins, np.argmin(hist) + 1)\n",
    "\n",
    "# print bins and count ordered by bin left value\n",
    "print(\"Bins:\")\n",
    "for i in range(len(bins) - 1):\n",
    "  print(f\"{bins[i]} - {bins[i + 1]}: {hist[i]}\")\n",
    "\n",
    "\n",
    "df_bins = pd.DataFrame()\n",
    "df_bins[\"BIN_LEFT\"] = bins[:-1]\n",
    "df_bins[\"BIN_RIGHT\"] = bins[1:]\n",
    "df_bins[\"COUNT\"] = hist\n",
    "\n",
    "# Calculate empirical probability of home win, draw and away win for each bin'\n",
    "df_bins[\"H_WINS\"] = df_bins[\"DRAWS\"] = df_bins[\"A_WINS\"] = 0.0\n",
    "\n",
    "for index, row in df_bins.iterrows():\n",
    "  df_bin = df_stats.loc[(df_stats[\"RATING_DIFF\"] >= row[\"BIN_LEFT\"]) & (df_stats[\"RATING_DIFF\"] < row[\"BIN_RIGHT\"])]\n",
    "  df_bins.loc[index, \"H_WINS\"] = df_bin.loc[df_bin[\"RESULT\"] == 1].shape[0] / df_bin.shape[0]\n",
    "  df_bins.loc[index, \"DRAWS\"] = df_bin.loc[df_bin[\"RESULT\"] == 0].shape[0] / df_bin.shape[0]\n",
    "  df_bins.loc[index, \"A_WINS\"] = df_bin.loc[df_bin[\"RESULT\"] == -1].shape[0] / df_bin.shape[0]\n",
    "\n",
    "df_bins.head(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write probabilities to csv\n",
    "df_bins.to_csv(\"Datasets/pi_rating_probabilities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the relationship between the rating difference and the probability of the home team winning\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df_bins[\"BIN_LEFT\"], df_bins[\"H_WINS\"], label=\"Home Win\")\n",
    "plt.plot(df_bins[\"BIN_LEFT\"], df_bins[\"DRAWS\"], label=\"Draw\")\n",
    "plt.plot(df_bins[\"BIN_LEFT\"], df_bins[\"A_WINS\"], label=\"Away Win\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# center arount 0, add a title and axis labels\n",
    "plt.xlim(-5, 5)\n",
    "plt.title(\"Probability of Home Win, Draw, Away Win\")\n",
    "plt.xlabel(\"Rating Difference\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
